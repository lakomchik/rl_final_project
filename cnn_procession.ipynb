{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, utils\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from img2vec_pytorch import Img2Vec\n",
    "import timm\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgarIoImagesLoader(DataLoader):\n",
    "    def __init__(self, history_len =5):\n",
    "        self.images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_len = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNRegression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNNRegression, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Take the last time step's output\n",
    "        return out\n",
    "    \n",
    "class Embeddings(torch.nn.Module):\n",
    "    def __init__(self, num_encoder_features = 512):\n",
    "        super().__init__()\n",
    "        self.encoder = timm.create_model('mobilenetv3_small', num_encoder_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "class HistoryEmbedding(torch.nn.Module):\n",
    "    def __init__(self, num_encoder_features = 512, history_len = 10):\n",
    "        super().__init__()\n",
    "        self.history_len = history_len\n",
    "        self.num_encoder_features = num_encoder_features\n",
    "        self.encoder = timm.create_model('resnet18', num_classes=num_encoder_features)\n",
    "        self.regressor = RNNRegression(num_encoder_features, self.history_len, 3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.stack([self.encoder(x[:,i,:,:,:]) for i in range(self.history_len)]).view(-1, self.history_len, self.num_encoder_features)\n",
    "        return self.regressor(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, data_dir,history_len, transform=None):\n",
    "        \n",
    "        self.num_images_per_folder = 1000\n",
    "        self.num_folders = 10\n",
    "        self.history_len = history_len\n",
    "        self.dataset_length = self.num_images_per_folder * self.num_folders\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_in_folder_idx = idx % self.num_images_per_folder\n",
    "        folder_idx = idx // self.num_images_per_folder\n",
    "        images = []\n",
    "        actions = []\n",
    "        \n",
    "        for i in range(img_in_folder_idx - self.history_len +1, img_in_folder_idx+1):\n",
    "            if(i < 0):\n",
    "                images.append(np.zeros((224,224,3), dtype=np.uint8))\n",
    "                actions.append(np.zeros((3), dtype=np.float32))\n",
    "            else:\n",
    "                img = Image.open(os.path.join(self.data_dir, f'episode_{folder_idx}','image', f'{i}.jpg'))\n",
    "                images.append(np.array(img))\n",
    "                actions.append(np.load(os.path.join(self.data_dir, f'episode_{folder_idx}','arr', f'{i}.npy'),allow_pickle=True)[0]['action'])\n",
    "            \n",
    "        if self.transform:\n",
    "            for i in range(len(images)):\n",
    "                images[i] = self.transform(images[i])\n",
    "                actions[i] = torch.tensor([0,0,0])#torch.from_numpy(actions[i])\n",
    "        images = torch.stack(images)\n",
    "        # In this example, we're just returning images without labels. \n",
    "        # You would typically also return labels in a real-world scenario.\n",
    "        actions = actions[-1].float()\n",
    "        return images, actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sample(data):\n",
    "    fig, axs = plt.subplots(1, history_len, figsize=(20, 20))\n",
    "    for i in range(history_len):\n",
    "        axs[i].imshow(data[0][i].permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Resize((224,224)),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "dataset = CustomImageDataset('data', history_len=history_len, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset, batch_size=16, shuffle=True, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HistoryEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ccb51958c02479fb9b47cda3cead897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/625 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # You can use other optimizers like SGD if desired\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "moedl = model.to(device)\n",
    "# Number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for batch_data, batch_labels in tqdm(data_loader):\n",
    "        # Transfer data and labels to GPU if one is available\n",
    "        \n",
    "        batch_data = batch_data.to(device)\n",
    "        batch_labels = batch_labels.to(device)\n",
    "\n",
    "        # 2. Training Loop\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        \n",
    "        predictions = model(batch_data)  # Get predictions from the model\n",
    "        \n",
    "        loss = loss_function(predictions, batch_labels)  # Compute the loss\n",
    "        loss.backward()  # Backpropagate the loss\n",
    "        optimizer.step()  # Update the model parameters\n",
    "        \n",
    "        total_loss += loss.item()  # Accumulate loss for monitoring\n",
    "    \n",
    "    # Print the average loss for this epoch\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
